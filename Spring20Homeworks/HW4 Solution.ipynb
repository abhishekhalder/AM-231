{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. [100 points] $\\mathcal{L}_{2}$ gain for LTI systems\n",
    "\n",
    "The purpose of this exercise is to revisit some details of the worst-case $\\mathcal{L}_{2}$ gain of LTI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [20 points] Bounding the worst-case $\\mathcal{L}_{2}$ gain\n",
    "\n",
    "In Lec. 9, p. 6, we mentioned (but did not prove) that the worst-case $\\mathcal{L}_{2}$ gain for a stable LTI system is\n",
    "\n",
    "$$\\gamma_{\\rm{LTI}} = \\|G(j\\omega)\\|_{\\infty} := \\underset{\\omega\\in\\mathbb{R}}{\\sup} \\sigma_{\\max}\\left(G(j\\omega)\\right), \\quad j:=\\sqrt{-1}, \\quad G(s) = C(sI-A)^{-1}B + D,$$\n",
    "\n",
    "where $G(j\\omega)$ is the associated transfer matrix. A proof of this fact can be done in two steps. In the first step, one shows that $\\|G(j\\omega)\\|_{\\infty}$ is a weak upper bound of the $\\mathcal{L}_{2}$ gain for any nonzero $u(t)\\in\\mathcal{L}_{2}[0,\\infty)$. The second step is to show that in fact an equality is achieved. In this part (a), we will only do the first step (upper bound). Specifically, **prove that**\n",
    "$$ \\dfrac{\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}}{\\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}} \\leq \\|G(j\\omega)\\|_{\\infty},$$\n",
    "\n",
    "and from there, conclude that $\\underset{\\stackrel{u(t)\\in\\mathcal{L}_{2}[0,\\infty)}{u(t)\\not\\equiv 0}}{\\sup} \\dfrac{\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}}{\\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}} \\leq \\|G(j\\omega)\\|_{\\infty}$.\n",
    "\n",
    "(Hint: Use Parseval's identity: for any causal signal $z(t)\\in\\mathcal{L}_{2}[0,\\infty)$, we have $\\int_{0}^{\\infty}z^{\\top}(t)z(t){\\rm{d}}t = \\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}Z^{*}(j\\omega)Z(j\\omega){\\rm{d}}\\omega$, where the superscript $*$ denotes the conjugate transpose, and the Fourier transform $Z(j\\omega) := \\int_{0}^{\\infty}z(t)e^{-j\\omega t}{\\rm{d}}t$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (a):\n",
    "\n",
    "To prove the inequality $\\dfrac{\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}}{\\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}} \\leq \\|G(j\\omega)\\|_{\\infty}$, notice that\n",
    "\n",
    "$$\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}^{2} = \\int_{0}^{\\infty}y^{\\top}(t)y(t){\\rm{d}}t = \\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}Y^{*}(j\\omega)Y(j\\omega){\\rm{d}}\\omega = \\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}U^{*}(j\\omega)G^{*}(j\\omega)G(j\\omega)U(j\\omega){\\rm{d}}\\omega,$$\n",
    "\n",
    "where the second equality is due to Parseval's identity, and the last equality uses $Y(j\\omega) = G(j\\omega)U(j\\omega)$.\n",
    "\n",
    "Since the last integrand is a quadratic form invovling a Hermitian matrix $G^{*}(j\\omega)G(j\\omega)$, we must have \n",
    "\n",
    "$$\\begin{align*}\n",
    "U^{*}(j\\omega)G^{*}(j\\omega)G(j\\omega)U(j\\omega) \\leq \\lambda_{\\max}\\left(G^{*}(j\\omega)G(j\\omega)\\right)U^{*}(j\\omega)U(j\\omega) &= \\sigma_{\\max}^{2}\\left(G(j\\omega)\\right)U^{*}(j\\omega)U(j\\omega)\\\\\n",
    "&= \\|G(j\\omega)\\|_{2}^{2}U^{*}(j\\omega)U(j\\omega),\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "where the last equality follows from the definition of the induced 2-norm of matrix $G(j\\omega)$. Therefore,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}^{2} \\leq \\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}\\|G(j\\omega)\\|_{2}^{2}U^{*}(j\\omega)U(j\\omega){\\rm{d}}\\omega \\leq \\left(\\underset{\\omega\\in\\mathbb{R}}{\\sup}\\|G(j\\omega)\\|_{2}^{2}\\right)\\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}U^{*}(j\\omega)U(j\\omega){\\rm{d}}\\omega, \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "and upon using Parseval's identity $\\frac{1}{2\\pi}\\int_{-\\infty}^{+\\infty}U^{*}(j\\omega)U(j\\omega){\\rm{d}}\\omega = \\int_{0}^{\\infty}u^{\\top}(t)u(t){\\rm{d}}t = \\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}^{2}$, we obtain\n",
    "\n",
    "$$\\dfrac{\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}^{2}}{\\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}^{2}} \\leq \\underset{\\omega\\in\\mathbb{R}}{\\sup}\\|G(j\\omega)\\|_{2}^{2} =: \\|G(j\\omega)\\|_{\\infty}^{2} \\quad\\Rightarrow\\quad \\dfrac{\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}}{\\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}} \\leq \\|G(j\\omega)\\|_{\\infty},$$\n",
    "\n",
    "as desired.\n",
    "\n",
    "Since the above holds for all $u(t)\\in\\mathcal{L}_{2}[0,\\infty)$, it must also hold for any specific choice of $u(t)\\in\\mathcal{L}_{2}[0,\\infty)$, and hence $\\underset{\\stackrel{u(t)\\in\\mathcal{L}_{2}[0,\\infty)}{u(t)\\not\\equiv 0}}{\\sup} \\dfrac{\\|y(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}}{\\|u(t)\\|_{\\mathcal{L}_{2}[0,\\infty)}} \\leq \\|G(j\\omega)\\|_{\\infty}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [25 points] State-space reformulation\n",
    "\n",
    "From now on, let us assume $D=0$ (no direct feedthrough). The frequency domain formula for the worst-case $\\mathcal{L}_{2}$ gain given in Lec. 9, p. 6, is inconvenient for computation because it involves solving a possibly nonconvex nonlinear optimization problem in $\\omega$. Let us pursue more computationally friendly reformulation via state space approach.\n",
    "\n",
    "By specializing the $\\mathcal{L}_2$ gain theorem for nonlinear systems (Lec. 9, p. 8-9) for $f(x)=Ax$, $g(x)=B$, $h(x)=Cx$, and $V(x) = \\frac{1}{2}x^{\\top}P x$ where $P \\succ 0$, prove that **if** the following optimization problem:\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\underset{\\gamma,P}{\\text{minimize}}\\quad\\gamma\\\\\n",
    "&\\text{subject to}\\quad\\gamma > 0, \\quad P\\succ 0, \\quad PA + A^{\\top}P + \\frac{1}{\\gamma^2}PBB^{\\top}P + C^{\\top}C \\preceq 0,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "has unique solution, **then** the answer of this optimization problem gives the tightest upper bound of $\\mathcal{L}_2$ gain $\\gamma_{\\text{LTI}}$. \n",
    "\n",
    "(In fact, when the triple $(A,B,C)$ is minimal, meaning both controllable and observable, then the answer of this optimization problem equals $\\gamma_{\\text{LTI}}$, and hence equals $\\|G(j\\omega)\\|_{\\infty}$. But you can ignore this detail.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (b):\n",
    "\n",
    "We specialize the $\\mathcal{L}_2$ gain theorem for nonlinear systems (Lec. 9, p. 8-9) for $f(x)=Ax$, $g(x)=B$, $h(x)=Cx$, and $V(x) = \\frac{1}{2}x^{\\top}P x$ where $P \\succ 0$. Clearly, our specific $V$ satisfies $V(0) = 0, V (x \\neq 0) > 0$, and the Hamilton-Jacobi partial differential inequality reduces to\n",
    "\n",
    "$$\\frac{1}{2}x^{\\top}\\left(PA + A^{\\top}P + \\frac{1}{\\gamma^2}PBB^{\\top}P + C^{\\top}C\\right)x \\leq 0,$$\n",
    "\n",
    "which will hold for all $x\\in\\mathbb{R}^{n}$ iff \n",
    "\n",
    "$$PA + A^{\\top}P + \\frac{1}{\\gamma^2}PBB^{\\top}P + C^{\\top}C \\preceq 0.$$\n",
    "\n",
    "Thus for any $\\gamma > 0$ to be an upper bound of the $\\mathcal{L}_2$ gain of the LTI system, it must satisfy the feasibility conditions\n",
    "\n",
    "$$\\gamma > 0, \\quad P\\succ 0, \\quad PA + A^{\\top}P + \\frac{1}{\\gamma^2}PBB^{\\top}P + C^{\\top}C \\preceq 0.$$\n",
    "\n",
    "The tightest upper bound is obtained by minimizing Î³ subject to the above constraints. Hence the statement. (**Comment on the usage of the adjective \"tightest\":** the fact that this bound cannot be improved by choosing a different (non-quadratic) Lyapunov function follows from the converse Lyapunov theorem for LTI system, see e.g., HW1, Prob 3(d).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) [20 points] A useful lemma\n",
    "\n",
    "At first glance, it may seem that the optimization problem in part (b) is nonlinear in both variables: scalar $\\gamma$ and matrix $P$, due to the last inequality constraint. However, this difficulty can be overcome via the following lemma.\n",
    "\n",
    "**Lemma statement:** Consider real square matrices $Q, R, S$ with $Q$ and $R$ symmetric. The linear matrix inequality $\\begin{pmatrix}Q & S\\\\S^{\\top} & R\\end{pmatrix} \\succeq 0$ is equivalent to (if and only if) $R \\succ 0$ and $Q - SR^{-1}S^{\\top}\\succeq 0$.\n",
    "\n",
    "**Prove this lemma**.\n",
    "\n",
    "(Hint: You may find the following facts useful. Fact 1: For a symmetric matrix $X$, the congruence transformation $X \\mapsto MXM^{\\top}$ via any invertible matrix $M$, preserves the matrix inertia, i.e., the numbers of positive, negative and zero eigenvalues of $X$, equal to the same for $MXM^{\\top}$. Fact 2: A block triangular matrix is non-singular iff its diagonal blocks are non-singular. Fact 3: A block diagonal matrix is positive semi-definite iff its diagonal blocks are positive semi-definite.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (c):\n",
    "\n",
    "($\\Rightarrow$)\n",
    "\n",
    "Suppose that $X:= \\begin{pmatrix}Q & S\\\\S^{\\top} & R\\end{pmatrix} \\succeq 0$, where the matrices $Q,R$ are symmetric, and $R$ is invertible (implicit in the inequality involving $R^{-1}$). Notice that Fact 1 in hint specialized to symmetric sign-definite matrices says that \"sign-definiteness is preserved under congruence transformation via any nonsingular matrix\". Now let $M:= \\begin{pmatrix}\n",
    "I & -SR^{-1}\\\\\n",
    "0 & I\n",
    "\\end{pmatrix}$, which by Fact 2 is non-singular. Then by Fact 1, we have\n",
    "\n",
    "$$X:= \\begin{pmatrix}Q & S\\\\S^{\\top} & R\\end{pmatrix} \\succeq 0 \\Leftrightarrow MXM^{\\top} = \\begin{pmatrix}\n",
    "I & -SR^{-1}\\\\\n",
    "0 & I\n",
    "\\end{pmatrix}\\begin{pmatrix}Q & S\\\\S^{\\top} & R\\end{pmatrix}\\begin{pmatrix}\n",
    "I & 0\\\\\n",
    "-R^{-1}S^{\\top} & I\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "Q - SR^{-1}S^{\\top} & 0\\\\\n",
    "0 & R\n",
    "\\end{pmatrix}\\succeq 0,$$\n",
    "\n",
    "which by Fact 3 further implies $R \\succeq 0$ and $Q - SR^{-1}S^{\\top}\\succeq 0$. Now, $R\\succeq 0$ together with the requirement that it is also invertible yields $R \\succ 0$. Therefore,\n",
    "$$\\begin{pmatrix}Q & S\\\\S^{\\top} & R\\end{pmatrix} \\succeq 0 \\quad\\Rightarrow\\quad R \\succ 0\\quad\\text{and}\\quad Q - SR^{-1}S^{\\top}\\succeq 0.$$\n",
    "\n",
    "($\\Leftarrow$)\n",
    "\n",
    "Suppose that $R \\succ 0$ and $Q - SR^{-1}S^{\\top}\\succeq 0$. Then by Fact 3, $Y := \\begin{pmatrix}\n",
    "Q - SR^{-1}S^{\\top} & 0\\\\\n",
    "0 & R\n",
    "\\end{pmatrix}\\succeq 0$. On the other hand, by Fact 2, the matrix $N := \\begin{pmatrix}\n",
    "I & SR^{-1}\\\\\n",
    "0 & I\n",
    "\\end{pmatrix}$ in nonsingular. Therefore, by Fact 1, we have:\n",
    "\n",
    "$$NYN^{\\top} = \\begin{pmatrix}\n",
    "I & SR^{-1}\\\\\n",
    "0 & I\n",
    "\\end{pmatrix} \\begin{pmatrix}\n",
    "Q - SR^{-1}S^{\\top} & 0\\\\\n",
    "0 & R\n",
    "\\end{pmatrix} \\begin{pmatrix}\n",
    "I & 0\\\\\n",
    "R^{-1}S^{\\top} & I\n",
    "\\end{pmatrix} = \\begin{pmatrix}Q & S\\\\S^{\\top} & R\\end{pmatrix} \\succeq 0.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) [15 points] Here comes LMI\n",
    "\n",
    "Using the lemma in part (c), and introducing $\\eta := \\gamma^{2}$, **show that** the optimization problem derived in part (b) is equivalent to the following optimization problem:\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\underset{\\eta,P}{\\text{minimize}}\\quad\\eta\\\\\n",
    "&\\text{subject to}\\quad\\eta > 0, \\quad P\\succ 0, \\quad \\begin{pmatrix}PA + A^{\\top}P + C^{\\top}C & PB\\\\\n",
    "B^{\\top}P & -\\eta I \n",
    "\\end{pmatrix}\\preceq 0,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "which is linear in both $\\eta,P$. Here $I$ denotes the identity matrix of appropriate dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (d):\n",
    "\n",
    "Setting $\\eta := \\gamma^2$, this follows immediately from the lemma in part (c) with $R:=\\eta I \\succ 0$, $Q := -\\left(A^{\\top}P + PA + C^{\\top}C\\right)$, and $S:=-PB$. Notice that such choices make $Q$ and $R$ symmetric matrices, as needed to apply the lemma. Furthermore, by the same lemma, the pair of matrix inequalities\n",
    "\n",
    "$$R:=\\eta I \\succ 0, \\quad (-Q) - (-S)R^{-1}(-S)^{\\top}\\geq 0,$$\n",
    "\n",
    "is equivalent to the single block matrix inequality\n",
    "\n",
    "$$\\begin{pmatrix}-(PA + A^{\\top}P + C^{\\top}C) & -PB\\\\\n",
    "-B^{\\top}P & \\eta I \n",
    "\\end{pmatrix}\\succeq 0\\quad\\Leftrightarrow\\begin{pmatrix}PA + A^{\\top}P + C^{\\top}C & PB\\\\\n",
    "B^{\\top}P & -\\eta I \n",
    "\\end{pmatrix}\\preceq 0,$$\n",
    "\n",
    "as claimed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) [20 points] Let us compute\n",
    "\n",
    "The type of optimization problem derived in part (d) is called semi-definite programming (SDP) problem that minimizes linear objective subject to linear matrix inequalities (LMIs). SDPs are convex optimization problems, and can be solved efficiently via software like cvx in MATLAB.\n",
    "\n",
    "Use the starter code provided to write a MATLAB code for computing the worst-case $\\mathcal{L}_{2}$ gain, i.e., the $\\mathcal{H}_{\\infty}$ norm of the given stable, controllable and observable LTI system in two ways: by using $\\texttt{cvx}$ to solve the optimization in part (d), and by using MATLAB command $\\texttt{norm(sys,inf)}$ to solve the frequency domain optimization problem. To understand how to specify an SDP in cvx, you may want to take a look at: http://cvxr.com/cvx/examples/ (Also, you may want to look at HW2 code for switched linear systems.)\n",
    "\n",
    "Report the $\\mathcal{H}_{\\infty}$ norms computed from the two methods, and submit your code inside the same zipped folder.\n",
    "\n",
    "**The starter code $\\texttt{Hinf.m}$ containing the LTI system is in CANVAS Files section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (e):\n",
    "\n",
    "Both MATLAB $\\texttt{norm(sys,inf)}$ and cvx SDP solutions produce the same answer: $\\|G(j\\omega)\\|_{\\infty} = 12.1843$. The completed code $\\texttt{Hinf.m}$ is available in the CANVAS Files section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
